\documentclass{article}


\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}

\graphicspath{{media/}}     % organize your images and other figures under media/ folder

  
%% Title
\title{Speech separation in real time using deep learning architectures
%%%% Cite as
%%%% Update your official citation here when published 
\thanks{\textit{\underline{Citation}}: 
\textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
  Jose Alberto Arango Sánchez\\
  Student of Computer science \\
  Unversity of Antioquia \\
  Medellín\\
  \texttt{jose.arangos@udea.edu.co} \\
  %% examples of more authors
   \And
  Julián David Arias Londoño \\
  Ph.D \\
  Unversity of Antioquia \\
  Medellín\\
  \texttt{julian.ariasl@udea.edu.co} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}


\begin{document}


\begin{abstract}
Speaker Separation/Multitalker separation is a task that consists of separating in different audios, the individual interventions of the speakers involved from an auditory mixture. This task would allow to improve the interaction between humans and systems, through speech, since it would serve as an information filter.

\end{abstract}


% keywords can be removed
\keywords{Speaker separation \and Single-channel \and Deep learning \and Real time \and Corpus Calls Spanish \and Speakers similitude \and Voice embeddings}


\section{Introduction}


\section{Base architecture}

\subsection{Conv-TasNet}


\section{Similitude between speakers}

\subsection{Speech Embeddings}

\subsubsection{Wav2Vec 2.0}
\subsubsection{Pyannote}

\section{Conv-TasNet modified}




\section{Experiments}

\subsection{Corpus phone calls}



\section{Results}

\subsection{Conv-TasNet}
\subsection{Conv-TasNet modified}

\section{Deploy}




\section{Conclusion}
Your conclusion here

\section*{Acknowledgments}
This was was supported in part by......

%Bibliography
\bibliographystyle{unsrt}  
\bibliography{references}  

\end{document}
